{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46aa3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_grades():\n",
    "    \"\"\"\n",
    "    Read student_grades csv file into a pandas DataFrame,\n",
    "    drop student_id column, replace whitespaces with NaN values,\n",
    "    drop any rows with Null values, convert all columns to int64,\n",
    "    return cleaned student grades DataFrame.\n",
    "    \"\"\"\n",
    "    # Acquire data from csv file.\n",
    "    grades = pd.read_csv(\"student_grades.csv\")\n",
    "\n",
    "    # Replace white space values with NaN values.\n",
    "    grades = grades.replace(r\"^\\s*$\", np.nan, regex=True)\n",
    "\n",
    "    # Drop all rows with NaN values.\n",
    "    df = grades.dropna()\n",
    "\n",
    "    # Convert all columns to int64 data types.\n",
    "    df = df.astype(\"int\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8504b6aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'student_grades.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m grades \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstudent_grades.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'student_grades.csv'"
     ]
    }
   ],
   "source": [
    " grades = pd.read_csv(\"student_grades.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96374c1a-fcba-46a1-af9e-33d34d8560c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering\n",
    "\n",
    "For some definitions, handling outliers and missing values, scaling, and encoding may be considered feature engineering. Here we'll draw a distinction between data preparation, data preprocessing, and feature engineering.\n",
    "\n",
    "- **data preparation**: the basic data cleaning necessary to get our data ready for exploration/analysis, e.g. correcting data types, fixing typos\n",
    "- **data preprocessing**: further data transformation done for the sake of modeling, as oppsoed to exploration/analysis, e.g. scaling, imputing, encoding\n",
    "- **feature engineering**: adding, combining, or removing features; usually with the help of domain knowledge\n",
    "\n",
    "Feature engineering can happen as part of data exploration or modeling, and engineered featured are also commonly explored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0129d56",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Some examples of feature engineering by this definition:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10038b9a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- domain-based conversion (example: farenheit to celsius, BMI calculation, log transformation)\n",
    "- domain based cutoffs (example: age >= 18 = is_adult; also dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd20c31",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- add / subtract (example: zillow dataset: beds + baths = room_count; total_sqft - 200 * bedrooms - 40 * bathrooms = living_area)\n",
    "- combine as booleans as a count (example: telco_churn: streaming + backups + ...  = service_count)\n",
    "- multiply / divide (example: tips dataset: total_bill / size = price_per_person)\n",
    "- ratios (example: tips dataset: tip / total_bill = tip percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f264d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Simplify!\n",
    "\n",
    "- categorical with many unique values to top 3 + \"Other\"\n",
    "- categorical to boolean: pool count -> has pool\n",
    "- continous -> categorical via binning (aka quantization or discretization) (example: income -> high, medium, low earner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4104eb-91b5-4168-b53f-2a11597bfacb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "In this lesson we'll cover some *automated* **feature selection** methods, that is, methods for determining which features are the most important.\n",
    "\n",
    "- SelectKBest\n",
    "- Recursive Feature Elimination\n",
    "- Sequential Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa80d1-b98d-48e1-a4b9-294bd379c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycols = ['col1', 'col2', 'col3', 'col4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5705fde2-e27b-4a53-900f-486532073d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start with initializing empty lists\n",
    "# # feature space will contain our features\n",
    "# feature_space = []\n",
    "# # scores will contain model performance\n",
    "# scores = []\n",
    "# # iterate through the list of columns:\n",
    "# for col in mycols:\n",
    "#     # add a new feature in each cycle\n",
    "#     feature_space.append(col)\n",
    "#     # fit a model based on the new feature space\n",
    "#     model_object.fit(X[feature_space], y)\n",
    "#     # get the score for that model\n",
    "#     scores.append(model_object.score(X[feature_space], y))\n",
    "    \n",
    "# my_scores = dict(zip(feature_space, scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed3a33a-2ca3-4625-94fd-def89bb5b497",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7018acce-d54f-4f9c-b9b8-ee2658d22d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wrangle\n",
    "from sklearn.feature_selection import SelectKBest, RFE, f_regression, SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59534ad5-8a6b-438f-b294-079988191ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = wrangle_grades()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b96c1-de4a-44d8-85ff-78b0f0c59c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_validate, test = train_test_split(df)\n",
    "# train, validate = train_test_split(train_validate)\n",
    "\n",
    "train, validate, test = wrangle.split_continuous(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0194745d-b17c-4ef8-bdca-c2ffc73eeee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e0868-2b09-4490-bd4c-4d58827a99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train[['exam1', 'exam2', 'exam3']], train.final_grade\n",
    "X_validate, y_validate = validate[['exam1', 'exam2', 'exam3']], validate.final_grade\n",
    "X_test, y_test = test[['exam1', 'exam2', 'exam3']], test.final_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc4ebee-12bc-432e-9631-e6c8adb10021",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Select K Best\n",
    "\n",
    "- looks at each feature in isolation against the target based on correlation\n",
    "- fastest of all approaches covered in this lesson\n",
    "- doesn't consider feature interactions\n",
    "- After fitting: `.scores_`, `.pvalues_`, `.get_support()`, and `.transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf4a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the thing\n",
    "kbest = SelectKBest(f_regression, k=2)\n",
    "# fit the thing\n",
    "_ = kbest.fit(X_train, y_train)\n",
    "# statistical f-value:\n",
    "kbest.scores_\n",
    "#p value: \n",
    "kbest.pvalues_\n",
    "kbest_results = pd.DataFrame(\n",
    "    dict(p=kbest.pvalues_, f=kbest.scores_),\n",
    "                             index = X_train.columns)\n",
    "kbest_results\n",
    "# get-support() will output a boolean mask to tell me which features were selected\n",
    "# we can apply this mask to the columns in our original dataframe\n",
    "X_train.columns[kbest.get_support()]\n",
    "# kbest transform will convert our information to the selected feature subspace\n",
    "# ****buuuuuut, its just a numpy array\n",
    "kbest.transform(X_train)[:5]\n",
    "X_train_transformed = pd.DataFrame(\n",
    "    kbest.transform(X_train),\n",
    "    columns=X_train.columns[kbest.get_support()],\n",
    "    index=X_train.index\n",
    ")\n",
    "X_train_transformed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e45b90-79ff-46e9-8d34-4b29fcd75e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the thing\n",
    "kbest = SelectKBest(f_regression, k=2)\n",
    "# fit the thing\n",
    "_ = kbest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dcf0dc-fc42-42fb-b1ab-e5dde8f186c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical f-value:\n",
    "kbest.scores_\n",
    "#p value: \n",
    "kbest.pvalues_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb3a8b-6fb1-4758-a6eb-2cbfdc407cda",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kbest_results = pd.DataFrame(\n",
    "    dict(p=kbest.pvalues_, f=kbest.scores_),\n",
    "                             index = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedde795-1285-41eb-b0f3-fd9edde23141",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "kbest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a07efc0-17e9-4b79-ba03-058c08fbcbcd",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# get-support() will output a boolean mask to tell me which features were selected\n",
    "# we can apply this mask to the columns in our original dataframe\n",
    "X_train.columns[kbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a1ad33-e05c-4748-8069-29b5355fa472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kbest transform will convert our information to the selected feature subspace\n",
    "# ****buuuuuut, its just a numpy array\n",
    "kbest.transform(X_train)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18824290-e7ff-4213-84d1-8969f63e9aa2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_train_transformed = pd.DataFrame(\n",
    "    kbest.transform(X_train),\n",
    "    columns=X_train.columns[kbest.get_support()],\n",
    "    index=X_train.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad85c8bc-e398-494a-9598-caad999564f9",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_train_transformed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a5069f-d6d6-49c4-aa81-76fdb806198b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RFE\n",
    "\n",
    "- Recursive Feature Elimination\n",
    "- Progressively eliminate features based on importance to the model\n",
    "- Requires a model with either a `.coef_` or `.feature_importances_` property\n",
    "- After fitting: `.ranking_`, `.get_support()`, and `.transform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f53395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a model object to use in RFE process.\n",
    "# The model is here to give us metrics on feature importance and model score\n",
    "# allowing us to recursively reduce the number of features to reach our desired space\n",
    "model = LinearRegression()\n",
    "\n",
    "# make thing\n",
    "rfe = RFE(model, n_features_to_select=2)\n",
    "# fit thing\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "rfe.ranking_\n",
    "\n",
    "pd.DataFrame(\n",
    "{\n",
    "    'rfe_ranking': rfe.ranking_\n",
    "},index = X_train.columns)\n",
    "\n",
    "rfe.get_support()\n",
    "\n",
    "X_train_transformed = pd.DataFrame(\n",
    "rfe.transform(X_train),\n",
    "index = X_train.index,\n",
    "columns = X_train.columns[rfe.support_])\n",
    "\n",
    "X_train_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa312fb-7ffe-42e1-ba75-1d9959d5817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c3953-6a49-466d-90b9-188429346832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a model object to use in RFE process.\n",
    "# The model is here to give us metrics on feature importance and model score\n",
    "# allowing us to recursively reduce the number of features to reach our desired space\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b23b48c-b13f-4f9c-b0f0-6d24f5ccc9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make thing\n",
    "rfe = RFE(model, n_features_to_select=2)\n",
    "# fit thing\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5de219-03ba-4945-8fb1-fc4060f36502",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc031df-50ac-4767-92ad-a8b67fa39639",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "{\n",
    "    'rfe_ranking': rfe.ranking_\n",
    "},index = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a00846-fdd4-44b6-868c-2a183509d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f386c9f6-bc2e-488f-9e8f-63d29367ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = pd.DataFrame(\n",
    "rfe.transform(X_train),\n",
    "index = X_train.index,\n",
    "columns = X_train.columns[rfe.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00a935d-44ef-430b-9095-c39805dc0433",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8d6e09-dab8-47d1-b7f4-8afca62d9d8c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sequential Feature Selector\n",
    "\n",
    "- progressively adds features based on cross validated model performance\n",
    "- forwards: start with 0, add the best additional feature until you have the desired number\n",
    "- backwards: start with all features, remove the worst performing until you have the desired number\n",
    "- After fitting: `.support_`, `.transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d0453-7ada-4b12-a9bd-09326ba9360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "sfs = SequentialFeatureSelector(model, n_features_to_select=2)\n",
    "sfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78019029-0d7f-4bbc-b2b1-921b78cbde0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = pd.DataFrame(\n",
    "sfs.transform(X_train),\n",
    "index = X_train.index,\n",
    "columns = X_train.columns[sfs.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2183f6-7e79-46de-b488-557c7a837e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d1a9a-9fa4-4c08-9680-c40300dcb5b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "- Simpler models handle change + variability better\n",
    "- Use RFE to narrow down your features and find the best ones, if your dataset is large (> 1GB; `df.info()`) use select k best instead\n",
    "- Remember: feature engineering is much more than feature selection!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
